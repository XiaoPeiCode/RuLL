# Type: args
global:
  random_seed: 42                  # Seed for random number generation
  need_preprocess: False            # Whether to preprocess the data, default is False since it only needs to be processed once

MCTS:
  TOTAL_: 0                         # Value added to the denominator when calculating rewards to avoid rules from small samples
  EPOCH: 50                         # Number of epochs for the MCTS process
  Early_termination_reward: 0.9      # Threshold for early termination based on reward
  reward_mode: 'train'              # Whether to calculate reward based on training or test set
  max_rule_len: 2                   # Maximum rule length for MCTS exploration

dataset:
  dataset_name: "HDFS"              # Name of the dataset used for training and testing
  dir: "dataset"                    # Directory path for the dataset
  total_num: 20000                  # Maximum number of log entries to use
  start_index: 0                    # Starting index for log extraction
  train_ratio: 0.9                  # Ratio of training data to the entire dataset
  test_num: 2000                    # Number of test samples to evaluate
  test_num_1: 25                    # Number of positive test cases (anomalies)
  test_num_0: 25                    # Number of negative test cases (normal logs)
  # test_start: 222500              # Optional: start index for test set (currently commented out)
  # test_end: 223000                # Optional: end index for test set (currently commented out)
  # test_num: 30                    # Optional: another setting for number of test cases (currently commented out)

LLM:
  rule_base: './rule_base/HDFS_rules_target_1_EarlyR_0.95_e_500_max_rule_len_5.json'
                                     # Path to the rule base used for anomaly detection
  name: "gpt-35-turbo-20230613"      # LLM model name (GPT-3.5 or GPT-4 supported)
  # name: "gpt-4-20230613"           # Optional: alternative GPT-4 model (commented out)
  # engine: "gpt-4-20230613"         # Optional: specify engine for GPT-4 (commented out)

  max_tokens: 1500                   # Maximum number of tokens for the LLM's response
  prompt_strategys: ["HtT"]          # List of prompt strategies (e.g., "CoT", "simple guidelines")
  prompt_strategy: "CoT"             # Current strategy used for prompting the LLM (Chain of Thought)
  temperature: 0                     # Temperature for randomness in the LLM's output (0 = deterministic)
  top_p: 1                           # Probability mass for nucleus sampling (default 1)
  frequency_penalty: 0               # Penalty for using frequent tokens in the response
  presence_penalty: 0                # Penalty for encouraging the appearance of new topics
  max_retries: 10                    # Maximum number of retries for the LLM API calls
